{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Docs","text":""},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/","title":"Client-Side Grid","text":"<p>Title: Client-Side Grid Filtering, Sorting, and Pagination with Backend Offset-Based Pagination Date: 2025-06-16 Status: Accepted  </p>"},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#context","title":"Context","text":"<p>This decision addresses the approach to managing grid-level data interactions \u2014 specifically filtering, sorting, and pagination \u2014 for data-driven UI components.</p> <p>Two architectural options were considered for handling these features:</p> <ol> <li>Client-Side Handling \u2013 Load the dataset once from the API and allow all interactions (filtering, sorting, pagination) to occur entirely in the browser.  </li> <li>Server-Side Handling \u2013 Rely on backend API endpoints to execute filtering, sorting, and pagination for every user interaction.</li> </ol> <p>The system in question needs to handle datasets that may be large in some cases, but are typically manageable in size after user-driven filtering.</p>"},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#decision","title":"Decision","text":"<p>The architecture will implement client-side filtering, sorting, and pagination for grid components.</p> <p>To support this:</p> <ul> <li>The UI will include filter inputs and a \"Search\" button that users must use to initiate data retrieval.</li> <li>Upon clicking \"Search\", the frontend will send a request to the API including any provided filter criteria.</li> <li>The API will return a page of data (default size of 500 records or fewer) along with offset-based pagination metadata.</li> <li>All grid operations (filtering, sorting, pagination) will then be handled entirely client-side using the retrieved data.</li> </ul> <p>In addition:</p> <ul> <li>The API will implement standardized filtering and sorting behavior for all relevant endpoints. This ensures consistency and reusability of query logic across the application.</li> <li>Every API endpoint will support:</li> <li>Sorting via query parameters in ascending/descending order.</li> <li>Filtering on text fields (equality) and numeric fields (equality, greater than, less than, and range).</li> </ul> <p>If the total number of matching records exceeds the initial page size (default limit = 500), the API will not return an error. Instead, it will return a <code>nextPageUrl</code> that can be used to fetch additional pages of data.</p>"},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#reasoning","title":"Reasoning","text":""},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#performance-and-user-experience","title":"Performance and User Experience","text":"<ul> <li>Interactions like filtering and sorting are executed instantly in the browser, eliminating round trips to the server and improving responsiveness.</li> <li>Users control when and how data is retrieved, reducing backend load and improving perceived speed.</li> </ul>"},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#simplicity","title":"Simplicity","text":"<ul> <li>Reduces complexity in the frontend-to-backend interaction model.</li> <li>Decreases backend logic for grid state handling.</li> <li>Encourages standardization of query patterns across endpoints.</li> </ul>"},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#scalable-pagination","title":"Scalable Pagination","text":"<ul> <li>Using <code>offset</code> and <code>limit</code> enables scalable data retrieval while avoiding hard failures due to record caps.</li> <li>Providing metadata like <code>nextPageUrl</code> and <code>totalRecords</code> gives clients full control if they need to fetch more data explicitly.</li> </ul>"},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#rest-api-capabilities","title":"REST API Capabilities","text":"<p>Even though grid operations are handled client-side after data retrieval, the REST API will support consistent and standardized pagination, filtering, and sorting behavior:</p>"},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#filtering","title":"Filtering","text":"<ul> <li>Text fields: Supports equality match (<code>eq</code>)</li> <li>Numeric fields: Supports:</li> <li>Equality (<code>eq</code>)</li> <li>Greater than (<code>gt</code>)</li> <li>Less than (<code>lt</code>)</li> <li>Range filtering (e.g., <code>min</code>/<code>max</code> or <code>between</code> operators)</li> </ul>"},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#sorting","title":"Sorting","text":"<ul> <li>Query parameter format: <code>?sort=field.asc</code> or <code>?sort=field.desc</code></li> <li>Multiple sort keys may be supported where applicable.</li> </ul>"},{"location":"Front%20End%20ADR%27s/Client%20Side%20Grid%20Handling/#pagination-offset-based","title":"Pagination (Offset-Based)","text":"<ul> <li>Default <code>limit</code>: 500</li> <li>Supports <code>limit</code> and <code>offset</code> parameters</li> <li>The API response includes:</li> </ul> <p>```json {   \"data\": [ / array of records / ],   \"offset\": 0,   \"limit\": 500,   \"totalRecords\": 1342,   \"hasMore\": true,   \"nextPageUrl\": \"/api/items?offset=500&amp;limit=500\",   \"previousPageUrl\": null,   \"filtersApplied\": {     \"status\": \"active\"   },   \"sort\": \"createdAt.desc\" }</p>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/","title":"Client-Side Grid Filtering 2","text":"<p>Title: Client-Side Grid Filtering, Sorting, and Pagination with Backend Record Limit Enforcement Date: 2025-06-16 Status: Accepted  </p>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#context","title":"Context","text":"<p>This decision addresses the approach to managing grid-level data interactions \u2014 specifically filtering, sorting, and pagination \u2014 for data-driven UI components.</p> <p>Two architectural options were considered for handling these features:</p> <ol> <li>Client-Side Handling \u2013 Load the dataset once from the API and allow all interactions (filtering, sorting, pagination) to occur entirely in the browser.  </li> <li>Server-Side Handling \u2013 Rely on backend API endpoints to execute filtering, sorting, and pagination for every user interaction.</li> </ol> <p>The system in question needs to handle datasets that may be large in some cases, but are typically manageable in size (&lt;500 records after filtering).</p>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#decision","title":"Decision","text":"<p>The architecture will implement client-side filtering, sorting, and pagination for grid components.</p> <p>To support this:</p> <ul> <li>The UI will include filter inputs and a \"Search\" button that users must use to initiate data retrieval.</li> <li>Upon clicking \"Search\", the frontend will send a request to the API including any provided filter criteria.</li> <li>The API will return a dataset (up to 500 records), which will be loaded into the client.</li> <li>All grid operations (filtering, sorting, pagination) will then be handled entirely client-side using the retrieved data.</li> </ul> <p>In addition:</p> <ul> <li>The API will implement standardized filtering and sorting behavior for all relevant endpoints. This ensures consistency and reusability of query logic across the application.</li> <li>Every API endpoint will support:</li> <li>Sorting via query parameters in ascending/descending order.</li> <li>Filtering on text fields (equality) and numeric fields (equality, greater than, less than, and range).</li> </ul> <p>This approach ensures that users have a mechanism to narrow their result sets before the client attempts to render or operate on the data, helping avoid hitting the 500-record API response limit, while also providing a robust and extensible backend interface.</p>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#reasoning","title":"Reasoning","text":""},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#performance-and-user-experience","title":"Performance and User Experience","text":"<ul> <li>Interactions like filtering and sorting are executed instantly in the browser, eliminating round trips to the server and improving responsiveness.</li> <li>For most use cases, the amount of data returned will remain within a tolerable size (500 records or fewer).</li> </ul>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#simplicity","title":"Simplicity","text":"<ul> <li>Reduces complexity in the frontend-to-backend interaction model.</li> <li>Decreases backend logic for grid state handling.</li> <li>Minimizes API call frequency, especially during repeated user interactions like re-sorting and incremental filtering.</li> </ul>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#api-record-limit-handling","title":"API Record Limit Handling","text":"<ul> <li>The REST API will enforce a default maximum return size of 500 records per request.</li> <li>If a client request results in more than 500 records being returned:</li> <li>The API will truncate the dataset to the first 500 records.</li> <li>A warning response will be included, indicating that the full dataset was not returned and suggesting the need for more precise filters.</li> </ul>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#rest-api-capabilities","title":"REST API Capabilities","text":"<p>Even though client-side grid operations are being used, the REST API will still support standardized query options to enable reusable and predictable behavior across endpoints:</p>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#filtering","title":"Filtering","text":"<ul> <li>Text fields: Supports equality match (<code>eq</code>)</li> <li>Numeric fields: Supports:</li> <li>Equality (<code>eq</code>)</li> <li>Greater than (<code>gt</code>)</li> <li>Less than (<code>lt</code>)</li> <li>Range filtering (e.g., <code>min</code>/<code>max</code> parameters or range object)</li> </ul>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#sorting","title":"Sorting","text":"<ul> <li>Supports sorting on eligible fields in both ascending and descending order (e.g., <code>?sort=name.asc</code>, <code>?sort=createdAt.desc</code>)</li> </ul>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#pagination","title":"Pagination","text":"<ul> <li>Optional pagination parameters (<code>limit</code>, <code>offset</code>) will be accepted but capped at a maximum of 500 records per response.</li> </ul> <p>These capabilities will be beneficial for more advanced use cases or if a future move to full server-side grid interaction is needed.</p>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#consequences","title":"Consequences","text":""},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#advantages","title":"Advantages","text":"<ul> <li>Fast and fluid user interactions without needing repeated API calls.</li> <li>Lower backend load due to fewer calls.</li> <li>Enables consistent client-side logic and simpler debugging.</li> <li>Provides foundational backend filter/sort capabilities that can be reused elsewhere or scaled later.</li> </ul>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#trade-offs","title":"Trade-Offs","text":"<ul> <li>Large unfiltered datasets may result in incomplete results due to the 500-record API limit.</li> <li>Client memory usage may increase with larger datasets.</li> <li>Users must apply meaningful filters to ensure they are working with the full intended dataset.</li> </ul>"},{"location":"Front%20End%20ADR%27s/ClientSideDataGrid/#framework-stack-notes","title":"Framework &amp; Stack Notes","text":"<p>The following technologies are being used to implement this architecture:</p> <ul> <li>Frontend: React with Ant Design Table for UI grid components.  </li> <li>Backend: RESTful API implemented with NestJS.  </li> <li>Communication: JSON-based REST over HTTPS, with standard query parameters for filtering, sorting, and pagination.</li> </ul>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/","title":"Long Running Operations - LRO's","text":"<p>Title: Long Running Operations Date: 2025-06-16 Status: Accepted  </p>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#context","title":"Context","text":"<p>This decision addresses the approach to managing grid-level data interactions \u2014 specifically filtering, sorting, and pagination \u2014 for data-driven UI components.</p> <p>Two architectural options were considered for handling these features:</p> <p>Client-Side Handling \u2013 Load the dataset once from the API and allow all interactions (filtering, sorting, pagination) to occur entirely in the browser. Server-Side Handling \u2013 Rely on backend API endpoints to execute filtering, sorting, and pagination for every user interaction. The system in question needs to handle datasets that may be large in some cases, but are typically manageable in size after user-driven filtering.</p>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#decision","title":"Decision","text":"<p>The architecture will implement client-side filtering, sorting, and pagination for grid components.</p> <p>To support this:</p> <p>The UI will include filter inputs and a \"Search\" button that users must use to initiate data retrieval. Upon clicking \"Search\", the frontend will send a request to the API including any provided filter criteria. The API will return a page of data (default size of 500 records or fewer) along with offset-based pagination metadata. All grid operations (filtering, sorting, pagination) will then be handled entirely client-side using the retrieved data. In addition:</p> <p>The API will implement standardized filtering and sorting behavior for all relevant endpoints. This ensures consistency and reusability of query logic across the application. Every API endpoint will support: Sorting via query parameters in ascending/descending order. Filtering on text fields (equality) and numeric fields (equality, greater than, less than, and range). If the total number of matching records exceeds the initial page size (default limit = 500), the API will not return an error. Instead, it will return a nextPageUrl that can be used to fetch additional pages of data.</p>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#reasoning","title":"Reasoning","text":""},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#performance-and-user-experience","title":"Performance and User Experience","text":"<p>Interactions like filtering and sorting are executed instantly in the browser, eliminating round trips to the server and improving responsiveness. Users control when and how data is retrieved, reducing backend load and improving perceived speed.</p>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#simplicity","title":"Simplicity","text":"<p>Reduces complexity in the frontend-to-backend interaction model. Decreases backend logic for grid state handling. Encourages standardization of query patterns across endpoints.</p>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#scalable-pagination","title":"Scalable Pagination","text":"<p>Using offset and limit enables scalable data retrieval while avoiding hard failures due to record caps. Providing metadata like nextPageUrl and totalRecords gives clients full control if they need to fetch more data explicitly.</p>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#rest-api-capabilities","title":"REST API Capabilities","text":"<p>Even though grid operations are handled client-side after data retrieval, the REST API will support consistent and standardized pagination, filtering, and sorting behavior:</p>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#filtering","title":"Filtering","text":"<p>Text fields: Supports equality match (eq) Numeric fields: Supports: Equality (eq) Greater than (gt) Less than (lt) Range filtering (e.g., min/max or between operators)</p>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#sorting","title":"Sorting","text":"<p>Query parameter format: ?sort=field.asc or ?sort=field.desc Multiple sort keys may be supported where applicable.</p>"},{"location":"Front%20End%20ADR%27s/LRO%20Long%20Running%20Operations/#pagination-offset-based","title":"Pagination (Offset-Based)","text":"<p>Default limit: 500 Supports limit and offset parameters The API response includes: ```json {   \"data\": [ / array of records / ],   \"offset\": 0,   \"limit\": 500,   \"totalRecords\": 1342,   \"hasMore\": true,   \"nextPageUrl\": \"/api/items?offset=500&amp;limit=500\",   \"previousPageUrl\": null,   \"filtersApplied\": {     \"status\": \"active\"   },   \"sort\": \"createdAt.desc\" }</p> <p>Edit</p> <p>ADR Template Document  I've created a comprehensive ADR template based on the structure from your example. The template includes all the key sections and provides guidance on what to include in each part:</p> <p>Header section with title, date, and status Context for describing the problem and options considered Decision stating what was chosen Reasoning explaining why (with subsections for different benefit categories) Consequences covering both positive and negative impacts Implementation Notes for technical details Related Decisions for linking to other ADRs References for external sources The template uses placeholder text in brackets to guide you on what content to include in each section. You can customize it further based on your team's specific needs or standards.</p> <p>Architectural Design Record (ADR) Title: [Brief descriptive title of the architectural decision] Date: [YYYY-MM-DD] Status: [Proposed | Accepted | Rejected | Deprecated | Superseded]</p> <p>Context [Describe the situation that requires a decision to be made. Include:]</p> <p>[What architectural problem or question needs to be addressed?] [What are the key factors, constraints, or requirements driving this decision?] [What options were considered?] [Any relevant background information or system context] Decision [State the architectural decision that has been made.]</p> <p>[Include specific details about:]</p> <p>[What approach will be implemented] [Key components or patterns involved] [Any specific technical requirements or constraints] [Implementation details that are crucial to the decision] Reasoning [Explain why this decision was made. Include:]</p> <p>[Benefit Category 1 (e.g., Performance, Maintainability, etc.)] [Specific reasoning points] [How this decision addresses the identified concerns] [Benefit Category 2] [Additional reasoning points] [Trade-offs considered] [Additional Categories as needed] [Other factors that influenced the decision] [Risks mitigated or accepted] Consequences [Describe the positive and negative consequences of this decision]</p> <p>Positive [Benefits gained from this approach] [Problems solved] [Improvements achieved] Negative [Trade-offs or limitations accepted] [New complexities introduced] [Technical debt or future considerations] Implementation Notes [Optional section for specific implementation details, if relevant:]</p> <p>[Technical specifications] [API contracts or interfaces] [Configuration requirements] [Migration considerations] [Example JSON schema, code snippets, or configuration examples can be included here]</p> <p>Related Decisions [Optional section linking to other ADRs:]</p> <p>[ADR-XXX: Related decision that this builds upon] [ADR-YYY: Decision that this supersedes or conflicts with] References [Optional section for external references:]</p> <p>[Documentation links] [Industry standards or patterns referenced] [Research or articles that influenced the decision]</p>"},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/","title":"Legacy AS/400 Reporting System Modernization","text":"<p>Title: Legacy AS/400 Reporting System Modernization Date: 2025-06-27 Status: In Progress  </p>"},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#context","title":"Context","text":"<p>This decision is about how we implement global reporting structure in the new application while integrating with legacy system. We are modernizing a legacy AS/400 (IBM i) system that currently uses SpoolFlex, an add-on application providing a 5250 terminal interface for spool file management. The existing system allows users to view/work with AS/400 spool files, convert to PDF/Excel formats, email reports, save to shared drives, and automate report generation through pre-defined jobs. </p> <p>The modernization effort aims to replace the outdated 5250 terminal interface completely with a modern web-based user interface while maintaining equivalent functionality.</p>"},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#decision","title":"Decision","text":"<p>We will implement a hybrid reporting architecture that bridges the legacy AS/400 system with modern web technologies. We will keep all existing functionality in-place and simply wrap the current system. This structure will also support our second phase of re-writing the existing RPG reports in a modern framework within our Node.js REST API backend.</p>"},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#core-components","title":"Core Components:","text":"<ol> <li>Tabular Report Log SQL Table - Central metadata repository:</li> <li> <p>Fields: ReportName, CreatedBy, Timestamp,FileName, LocationPath.</p> </li> <li> <p>Shared Drive Storage - File system location for converted report outputs</p> </li> <li> <p>*Note: the client and the applications moving reports to the share will need the appropriate security access.</p> </li> <li> <p>Legacy System Wrapper Program - Bridge component that accepts parameters (SpoolFileLocation, User, OutputPath, ConversionType), retrieves spool files, converts to desired format, generates timestamped filenames, saves to output path, and records metadata in SQL table</p> </li> <li> <p>Modern Backend API - RESTful service with GET endpoints for report log retrieval, filtering by report type/user permissions, and shared/private access control</p> </li> <li> <p>Web Client Interface - Browser-based UI component that displays available reports and opens them directly from shared drive locations. This should allow user to open the file folder location, open the report in a separate window, or popup download the report from the browser.</p> </li> </ol>"},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#reasoning","title":"Reasoning","text":""},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#report-log-benefits","title":"Report Log Benefits","text":"<p>The centralized report log provides a scalable foundation for future modernization. As we gradually migrate reports from the legacy system to native backend implementations, we can maintain the same process: write to the report log and save files to shared drive locations. This consistent approach ensures:</p> <ul> <li>Unified reporting interface regardless of report source (legacy or modern)</li> <li>Error tracking capabilities - failed report generations can be logged with error details</li> <li>Audit trail for all report activities across the entire system</li> <li>Seamless migration path without disrupting user workflows</li> </ul>"},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#alternatives-considered","title":"Alternatives Considered","text":"<p>Alternative 1: Direct File System Access - Pros: Users work directly with output files in storage locations - Cons: Requires page-specific mappings to share drive locations (not scalable), vulnerable to storage location changes, no global repository of report activities - Rejected: Duplicates Windows File Explorer functionality without added value</p>"},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#consequences","title":"Consequences","text":""},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#positive","title":"Positive","text":"<ul> <li>Gradual migration path without operational disruption</li> <li>Preserved functionality with modern user experience</li> <li>Scalable architecture supporting future report implementations</li> <li>Centralized error handling and audit capabilities</li> <li>Flexible output formats (PDF, HTML, CSV)</li> </ul>"},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#negative","title":"Negative","text":"<ul> <li>Maintains dependency on legacy AS/400 system</li> <li>Additional system complexity and potential failure points</li> <li>Ongoing shared drive storage management requirements</li> </ul>"},{"location":"REST%20API%20ADR%27s/Reporting%20System%20Modernization/#implementation-notes","title":"Implementation Notes","text":"<ol> <li>Implement Report Log SQL table and wrapper program</li> <li>Build RESTful backend service with filtering capabilities</li> <li>Develop web client interface</li> <li>Migrate automated jobs and optimize performance</li> </ol> <p>Review Date: Now</p>"},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/","title":"RPG Program and Database File Development Standards","text":"<p>Title: RPG Program and Database File Development Standards Date: 2025-07-14 Status: In Progress  </p>"},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/#context","title":"Context","text":"<p>Architectural Problem: Our current RPG application system relies on temporary flat files that need to be converted to externally defined permanent tables as part of our migration to a Power 10 server architecture. The existing system uses two distinct types of temporary files that require different handling approaches.</p> <p>Key Factors and Constraints: - Migration from temporary flat files to permanent database tables - Two types of temporary files requiring different conversion strategies:   1. Job-scoped tables (implementation approach TBD)   2. User-scoped temporary files (specific conversion requirements defined) - Multi-environment deployment across Power 8 (dev/test/UAT) and Power 10 (production) servers - Need for proper library management and naming conventions - Requirement to maintain data isolation and security</p> <p>Options Considered: - Continue with temporary files (rejected due to data persistence needs) - Convert all temporary files to permanent tables with same structure (rejected due to security concerns) - Implement differentiated approach based on file scope (selected)</p> <p>System Context: IBM i (AS/400) environment with RPG programs accessing database files across multiple environments, with production running on Power 10 and lower environments on Power 8.</p>"},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/#decision","title":"Decision","text":"<p>Architectural Decision: Implement a tiered database architecture with externally defined permanent tables, environment-specific library management, and differentiated handling of temporary file types.</p> <p>Implementation Approach:</p> <p>User-Scoped Temporary Files Conversion: - Convert to externally defined permanent tables - Add USER_NAME field to enable user-based data isolation - Store physical files in Working Data Library with \"G\" prefix - Create logical files/views in Data Library without prefix for RPG program access - Require user filtering in all INSERT/DELETE operations</p> <p>Job-Scoped Tables: - Status: To Be Determined - Permanent data sorts will be replaced with logical files (SQL views)</p> <p>Library Structure by Environment:</p> Environment Data Library Working Data Library Stored Procedure Library Server Development DATADEV QS36FDEV GSSLIBDEV Power 8 Testing DATATEST QS36FTEST GSSLIBTEST Power 8 UAT DATAUAT QS36FUAT GSSLIBUAT Power 8 Production DATA QS36F GSSLIB Power 10 <p>Technical Requirements: - All database files must be externally defined - RPG programs reference logical files in Data Library only - Physical files stored in Working Data Library with \"G\" prefix - User filtering mandatory for user-scoped table access</p>"},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/#reasoning","title":"Reasoning","text":"<p>Data Persistence and Integrity - Permanent tables provide data persistence beyond job/session scope - Externally defined tables ensure better data integrity and documentation - Structured approach to user data isolation improves security</p> <p>Maintainability and Scalability - Logical files provide abstraction layer for easier future modifications - Environment-specific libraries enable proper deployment control - Standardized naming conventions improve system maintainability - Power 10 architecture provides improved performance and capacity</p> <p>Security and Data Isolation - User-based filtering prevents cross-user data access - Separate library structure ensures environment isolation - Controlled access patterns through logical file abstraction</p> <p>Trade-offs Considered: - Increased storage requirements vs. improved data persistence - Additional development effort vs. long-term maintainability benefits - User filtering complexity vs. enhanced security</p> <p>Risk Mitigation: - Phased approach allows for testing and refinement - Deferred decision on job-scoped tables reduces immediate complexity - Environment separation minimizes deployment risks</p>"},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/#consequences","title":"Consequences","text":""},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/#positive","title":"Positive","text":"<ul> <li>Data Persistence: User-scoped data persists beyond individual sessions</li> <li>Improved Data Management: Externally defined tables provide better integrity and documentation</li> <li>Environment Isolation: Separate libraries ensure clean environment management and deployment control</li> <li>Enhanced Performance: Power 10 server provides improved performance and capacity for production</li> <li>Better Maintainability: Logical files provide abstraction layer for easier future modifications</li> <li>Enhanced Security: User-based filtering prevents unauthorized data access</li> </ul>"},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/#negative","title":"Negative","text":"<ul> <li>Development Effort: All programs referencing temporary files require modification for user filtering</li> <li>Storage Requirements: Permanent tables consume more storage than temporary files</li> <li>Increased Complexity: Additional user filtering logic required in all affected programs</li> <li>Migration Risk: Potential for data inconsistency during transition period</li> <li>Cross-Server Complexity: Different server architectures for development vs. production environments</li> </ul>"},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/#implementation-notes","title":"Implementation Notes","text":"<p>User-Scoped Table Conversion Process: 1. Create physical table in Working Data Library with \"G\" prefix (QS36FDEV/QS36FTEST/QS36FUAT/QS36F) 2. Add USER_NAME field to table structure 3. Create corresponding logical file/view in Data Library (DATADEV/DATATEST/DATAUAT/DATA) 4. Identify all programs referencing the temporary file 5. Modify programs to include user filtering logic 6. Test data access and filtering functionality 7. Deploy to appropriate environment libraries following promotion process</p> <p>RPG Program Modification Pattern: <pre><code>// Before (temporary file access)\nREAD TEMPFILE;\n\n// After (permanent table with user filtering)\nCLEAR CUSTFILE;\nUSER_NAME = %USERID();\nSETLL (USER_NAME) CUSTFILE;\nREAD CUSTFILE;\n</code></pre></p> <p>Library Usage Guidelines: - Data Library: Contains logical files/views (non-prefixed names) that RPG programs reference - Working Data Library: Contains physical tables with \"G\" prefix for actual data storage - Stored Procedure Library: Contains database stored procedures and functions</p> <p>Server Infrastructure: - Power 8 Server: Hosts Development, Testing, and UAT environments - Power 10 Server: Hosts Production environment only - Cross-Server Considerations: Development and testing occur on Power 8, with final deployment to Power 10 for production</p> <p>Deployment Process: - New programs must be developed with the new library structure - Existing programs migrated to appropriate environment libraries during deployment - Cross-environment consistency maintained through standardized naming conventions</p>"},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/#related-decisions","title":"Related Decisions","text":"<p>[To be added as additional ADRs are created]</p>"},{"location":"RPG%20Legacy%20ADR%27s/RPG%20Development%20Standards/#references","title":"References","text":"<p>[To be added as external documentation and standards are referenced]</p> <p>Future Considerations: - Job-scoped table implementation strategy needs definition - Performance monitoring requirements for user-filtered queries - Indexing strategy for USER_NAME fields - Data archiving approach for user-scoped permanent tables - Backup and recovery procedure updates for new table structure</p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/","title":"Authentication and Authorization","text":"<p>Title: Authentication and Authorization Security Standards Date: 2025-06-16 Status: Accepted  </p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/#context","title":"Context","text":"<p>This decision addresses the approach to managing grid-level data interactions \u2014 specifically filtering, sorting, and pagination \u2014 for data-driven UI components.</p> <p>Two architectural options were considered for handling these features:</p> <p>Client-Side Handling \u2013 Load the dataset once from the API and allow all interactions (filtering, sorting, pagination) to occur entirely in the browser. Server-Side Handling \u2013 Rely on backend API endpoints to execute filtering, sorting, and pagination for every user interaction. The system in question needs to handle datasets that may be large in some cases, but are typically manageable in size after user-driven filtering.</p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/#decision","title":"Decision","text":"<p>The architecture will implement client-side filtering, sorting, and pagination for grid components.</p> <p>To support this:</p> <p>The UI will include filter inputs and a \"Search\" button that users must use to initiate data retrieval. Upon clicking \"Search\", the frontend will send a request to the API including any provided filter criteria. The API will return a page of data (default size of 500 records or fewer) along with offset-based pagination metadata. All grid operations (filtering, sorting, pagination) will then be handled entirely client-side using the retrieved data. In addition:</p> <p>The API will implement standardized filtering and sorting behavior for all relevant endpoints. This ensures consistency and reusability of query logic across the application. Every API endpoint will support: Sorting via query parameters in ascending/descending order. Filtering on text fields (equality) and numeric fields (equality, greater than, less than, and range). If the total number of matching records exceeds the initial page size (default limit = 500), the API will not return an error. Instead, it will return a nextPageUrl that can be used to fetch additional pages of data.</p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/#reasoning","title":"Reasoning","text":""},{"location":"Security%20ADR%27s/Security%20End%202%20End/#performance-and-user-experience","title":"Performance and User Experience","text":"<p>Interactions like filtering and sorting are executed instantly in the browser, eliminating round trips to the server and improving responsiveness. Users control when and how data is retrieved, reducing backend load and improving perceived speed.</p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/#simplicity","title":"Simplicity","text":"<p>Reduces complexity in the frontend-to-backend interaction model. Decreases backend logic for grid state handling. Encourages standardization of query patterns across endpoints.</p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/#scalable-pagination","title":"Scalable Pagination","text":"<p>Using offset and limit enables scalable data retrieval while avoiding hard failures due to record caps. Providing metadata like nextPageUrl and totalRecords gives clients full control if they need to fetch more data explicitly.</p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/#rest-api-capabilities","title":"REST API Capabilities","text":"<p>Even though grid operations are handled client-side after data retrieval, the REST API will support consistent and standardized pagination, filtering, and sorting behavior:</p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/#filtering","title":"Filtering","text":"<p>Text fields: Supports equality match (eq) Numeric fields: Supports: Equality (eq) Greater than (gt) Less than (lt) Range filtering (e.g., min/max or between operators)</p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/#sorting","title":"Sorting","text":"<p>Query parameter format: ?sort=field.asc or ?sort=field.desc Multiple sort keys may be supported where applicable.</p>"},{"location":"Security%20ADR%27s/Security%20End%202%20End/#pagination-offset-based","title":"Pagination (Offset-Based)","text":"<p>Default limit: 500 Supports limit and offset parameters The API response includes: ```json {   \"data\": [ / array of records / ],   \"offset\": 0,   \"limit\": 500,   \"totalRecords\": 1342,   \"hasMore\": true,   \"nextPageUrl\": \"/api/items?offset=500&amp;limit=500\",   \"previousPageUrl\": null,   \"filtersApplied\": {     \"status\": \"active\"   },   \"sort\": \"createdAt.desc\" }</p> <p>Edit</p> <p>ADR Template Document  I've created a comprehensive ADR template based on the structure from your example. The template includes all the key sections and provides guidance on what to include in each part:</p> <p>Header section with title, date, and status Context for describing the problem and options considered Decision stating what was chosen Reasoning explaining why (with subsections for different benefit categories) Consequences covering both positive and negative impacts Implementation Notes for technical details Related Decisions for linking to other ADRs References for external sources The template uses placeholder text in brackets to guide you on what content to include in each section. You can customize it further based on your team's specific needs or standards.</p> <p>Architectural Design Record (ADR) Title: [Brief descriptive title of the architectural decision] Date: [YYYY-MM-DD] Status: [Proposed | Accepted | Rejected | Deprecated | Superseded]</p> <p>Context [Describe the situation that requires a decision to be made. Include:]</p> <p>[What architectural problem or question needs to be addressed?] [What are the key factors, constraints, or requirements driving this decision?] [What options were considered?] [Any relevant background information or system context] Decision [State the architectural decision that has been made.]</p> <p>[Include specific details about:]</p> <p>[What approach will be implemented] [Key components or patterns involved] [Any specific technical requirements or constraints] [Implementation details that are crucial to the decision] Reasoning [Explain why this decision was made. Include:]</p> <p>[Benefit Category 1 (e.g., Performance, Maintainability, etc.)] [Specific reasoning points] [How this decision addresses the identified concerns] [Benefit Category 2] [Additional reasoning points] [Trade-offs considered] [Additional Categories as needed] [Other factors that influenced the decision] [Risks mitigated or accepted] Consequences [Describe the positive and negative consequences of this decision]</p> <p>Positive [Benefits gained from this approach] [Problems solved] [Improvements achieved] Negative [Trade-offs or limitations accepted] [New complexities introduced] [Technical debt or future considerations] Implementation Notes [Optional section for specific implementation details, if relevant:]</p> <p>[Technical specifications] [API contracts or interfaces] [Configuration requirements] [Migration considerations] [Example JSON schema, code snippets, or configuration examples can be included here]</p> <p>Related Decisions [Optional section linking to other ADRs:]</p> <p>[ADR-XXX: Related decision that this builds upon] [ADR-YYY: Decision that this supersedes or conflicts with] References [Optional section for external references:]</p> <p>[Documentation links] [Industry standards or patterns referenced] [Research or articles that influenced the decision]</p>"},{"location":"Testing%20ARD%27s/UAT%20Process/","title":"User Acceptance Testing (UAT) Process","text":""},{"location":"Testing%20ARD%27s/UAT%20Process/#objective","title":"Objective","text":"<p>Ensure delivered functionality meets the Business Requirements Document (BRD) and is free from critical defects before go-live.</p>"},{"location":"Testing%20ARD%27s/UAT%20Process/#roles-responsibilities","title":"Roles &amp; Responsibilities","text":"<ul> <li>Business Users \u2013 Execute test cases, report issues, provide feedback.</li> <li>Internal ARG-QA \u2013 Bridge between Users and Consultant; verifies features before UAT, filters bugs, manages communication, and performs triage classification.</li> <li>Consultant QA (DAMCO) \u2013 Logs validated bugs into JIRA, investigates, resolves, and updates status.</li> </ul>"},{"location":"Testing%20ARD%27s/UAT%20Process/#process-flow","title":"Process Flow","text":"<ol> <li> <p>Smoke Test (DAMCO QA)    DAMCO QA verifies the environment is stable and major functionality works. Critical blockers are fixed before proceeding.</p> </li> <li> <p>Pre-UAT Verification (ARG-QA)    ARG-QA performs a quick functional check to confirm:  </p> </li> <li>Feature is accessible in UAT environment  </li> <li>Main buttons/links work  </li> <li>No blocking errors occur  </li> <li> <p>Core workflows are usable for testing  </p> </li> <li> <p>User Testing &amp; Logging Issues    Users execute test scenarios and log all issues (bugs, usability concerns, questions) into a shared OneDrive spreadsheet with:  </p> </li> <li>Steps taken  </li> <li>Expected vs. actual results  </li> <li> <p>Screenshots/data references</p> </li> <li> <p>ARG-QA Review &amp; Triage    ARG-QA reviews entries to:  </p> </li> <li>Remove duplicates  </li> <li>Identify misunderstandings  </li> <li> <p>Classify using the Triage Classification System (see below)</p> </li> <li> <p>UAT Review Meeting </p> </li> <li> <p>ARG-QA and Users meet to confirm classifications and finalize the issue list based on triage categories.</p> </li> <li> <p>Issue Resolution Based on Triage    Issues are handled according to their triage classification:</p> </li> <li>Clear and Communicate Immediately: <ul> <li>Category 1 (User Mis-Interpretation)</li> </ul> </li> <li>Send Directly to DAMCO: <ul> <li>Category 2 (Design Adherence)</li> <li>Category 3 (Clear Defect)</li> </ul> </li> <li> <p>Requires ARG Internal Review: </p> <ul> <li>Category 4 (Business Rule Implementation Error)</li> <li>Category 5 (Enhancement Request)</li> </ul> </li> <li> <p>Bug Resolution &amp; Tracking    DAMCO QA fixes issues, updates JIRA status, and coordinates with ARG-QA for validation.</p> </li> <li> <p>Bug Validation &amp; UAT Sign-Off    ARG-QA and Users re-test resolved items. UAT completes when:  </p> </li> <li>All critical/high defects are fixed and verified  </li> <li>No open medium/low defects block go-live  </li> <li>User sign-off is received</li> </ol>"},{"location":"Testing%20ARD%27s/UAT%20Process/#triage-classification-system","title":"Triage Classification System","text":"Classification Description Action Required 1 - User Mis-Interpretation User misunderstood functionality or process Clear Immediately with user education 2 - Design Adherence System not following approved design specifications Send Directly to DAMCO 3 - Clear Defect Obvious system malfunction or error Send Directly to DAMCO 4 - Business Rule Implementation Error System not implementing business rules correctly Requires ARG Internal Review 5 - Enhancement Request New functionality or improvement request Requires ARG Internal Review"},{"location":"Testing%20ARD%27s/UAT%20Process/#jira-status-tracking","title":"JIRA Status Tracking","text":"JIRA Status Description Required Action In-Progress DAMCO actively working on the issue Monitor progress ARG-QA Input Required DAMCO requires clarification from ARG ARG provides requested information Implemented Fix deployed to UAT environment REQUIRES ACTION: - ARG-QA Re-test and validate Resolved No Implementation Issue resolved without code changes ARG-QA Needs to confirm and mark done Done ARG has validated and closed the issue Update tracking spreadsheet"},{"location":"Testing%20ARD%27s/UAT%20Process/#tools-communication","title":"Tools &amp; Communication","text":"<ul> <li>OneDrive Spreadsheet \u2013 Centralized logging of all user-reported issues with triage classifications.</li> <li>JIRA \u2013 DAMCO QA's bug tracking system with standardized status workflow.</li> <li>QA Meetings / Teams \u2013 Communication between ARG-QA, Users, and DAMCO QA.</li> </ul>"},{"location":"Testing%20ARD%27s/UAT%20Process/#workflow-summary-by-triage-category","title":"Workflow Summary by Triage Category","text":"<p>Category 1 (User Mis-Interpretation): - OneDrive Entry \u2192 ARG-QA Review \u2192 Clear Immediately \u2192 User Communication</p> <p>Categories 2 &amp; 3 (Design Adherence / Clear Defect): - OneDrive Entry \u2192 ARG-QA Review \u2192 Direct DAMCO Submission \u2192 JIRA Tracking \u2192 Resolution \u2192 User Validation</p> <p>Categories 4 &amp; 5 (Business Rule Error / Enhancement):  - OneDrive Entry \u2192 ARG-QA Review \u2192 ARG Internal Review \u2192 Decision \u2192 Potential DAMCO Submission \u2192 JIRA Tracking (if applicable)</p>"}]}